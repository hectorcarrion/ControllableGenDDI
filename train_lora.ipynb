{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OplN-2GRj68"
      },
      "source": [
        "# Settup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRub62dxLiwk",
        "outputId": "54295d52-ca79-4858-f52f-bdcebef9ca9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'miccai-2025'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 73 (delta 40), reused 58 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (73/73), 177.78 KiB | 8.89 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hectorcarrion/ControllableGenDDI.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBOoSrhBoI6p",
        "outputId": "fb91380d-9c36-4358-a73e-5fc23e9871af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "The token `colab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `colab`\n"
          ]
        }
      ],
      "source": [
        "hf_token = # replace with your github token\n",
        "!huggingface-cli login --token {hf_token}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnM9z9H058Gn"
      },
      "source": [
        "# Train LoRA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes diffusers==0.22.0 huggingface_hub==0.25.0\n",
        "!pip uninstall -y peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyrtYPFulvvA",
        "outputId": "3b329aa4-d9d7-4440-fbbc-6ad3fac87d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diffusers==0.22.0\n",
            "  Downloading diffusers-0.22.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting huggingface_hub==0.25.0\n",
            "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (3.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (0.5.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.22.0) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (4.12.2)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.22.0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.22.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.22.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.22.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.22.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading diffusers-0.22.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, nvidia-cusolver-cu12, diffusers, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.32.2\n",
            "    Uninstalling diffusers-0.32.2:\n",
            "      Successfully uninstalled diffusers-0.32.2\n",
            "Successfully installed bitsandbytes-0.45.2 diffusers-0.22.0 huggingface_hub-0.25.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Found existing installation: peft 0.14.0\n",
            "Uninstalling peft-0.14.0:\n",
            "  Successfully uninstalled peft-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIm0AchM5-an"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import torch\n",
        "from safetensors import safe_open\n",
        "from safetensors.torch import save_file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 0\n",
        "SPLIT = f\"ddi_{SEED}\"\n",
        "\n",
        "OUTPUT_DIR_BASE = f\"..\"\n",
        "path = f\"{OUTPUT_DIR_BASE}/*/learned_embeds.safetensors\"\n",
        "target_path = f\"{OUTPUT_DIR_BASE}/aggregated_embeds_SEED={SEED}.pt\""
      ],
      "metadata": {
        "id": "Gne1seVr79UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_dict = dict()\n",
        "for file in glob.glob(path):\n",
        "    tensors = {}\n",
        "    with safe_open(file, framework=\"pt\", device=\"cpu\") as f:\n",
        "        for key in f.keys():\n",
        "            tensors[key] = f.get_tensor(key)\n",
        "        merged_dict.update(tensors)\n",
        "\n",
        "os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "torch.save(merged_dict, target_path)\n",
        "print(merged_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQrtVS2S8Ran",
        "outputId": "f32eff05-32f0-4352-d2e1-e6f5b43a8a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<abscess-class>': tensor([[ 0.0336, -0.0929,  0.0927,  ...,  0.1356, -0.1197, -0.0410]]), '<acne-cystic-class>': tensor([[ 0.0144, -0.0685,  0.0166,  ...,  0.0737,  0.0434, -0.0136]]), '<acquired_digital_fibrokeratoma-class>': tensor([[ 0.0837,  0.1314, -0.1585,  ...,  0.0369, -0.0451,  0.2210]]), '<acral_melanotic_macule-class>': tensor([[-0.0022,  0.0303, -0.0297,  ...,  0.0624,  0.1172, -0.1356]]), '<acrochordon-class>': tensor([[ 0.0146, -0.0569, -0.1451,  ..., -0.0315,  0.2035,  0.0306]]), '<actinic_keratosis-class>': tensor([[-0.0003, -0.0835,  0.0214,  ...,  0.0085,  0.1182,  0.0260]]), '<angioleiomyoma-class>': tensor([[-0.0522, -0.0379, -0.0166,  ...,  0.0870, -0.0146,  0.1065]]), '<angioma-class>': tensor([[-0.1210,  0.0884,  0.0724,  ..., -0.0136,  0.2079,  0.0167]]), '<arteriovenous_hemangioma-class>': tensor([[-0.1179, -0.1670, -0.0120,  ...,  0.0979,  0.1182, -0.1374]]), '<basal_cell_carcinoma-class>': tensor([[-0.0282, -0.1182,  0.0768,  ...,  0.0836,  0.0495,  0.0845]]), '<benign_keratosis-class>': tensor([[ 0.0019, -0.0196,  0.1209,  ...,  0.1479, -0.0314,  0.0413]]), '<blastic_plasmacytoid_dendritic_cell_neoplasm-class>': tensor([[-0.1127, -0.0374,  0.1607,  ...,  0.1160, -0.0021,  0.1852]]), '<blue_nevus-class>': tensor([[ 0.0348, -0.1444,  0.0464,  ...,  0.0016,  0.0864, -0.0485]]), '<cellular_neurothekeoma-class>': tensor([[-0.2534, -0.1371, -0.0305,  ..., -0.1461, -0.1077,  0.0896]]), '<chondroid_syringoma-class>': tensor([[-0.0712, -0.1676,  0.0120,  ..., -0.0395, -0.0136,  0.0669]]), '<clear_cell_acanthoma-class>': tensor([[-0.1071, -0.1095,  0.0300,  ...,  0.0999,  0.0842, -0.0213]]), '<coccidioidomycosis-class>': tensor([[-0.0661, -0.0521, -0.0582,  ...,  0.0365, -0.0088,  0.0133]]), '<condyloma_acuminatum-class>': tensor([[-0.1947, -0.0484,  0.1582,  ..., -0.0270,  0.0381,  0.0338]]), '<cutaneous_T-cell_lymphoma-class>': tensor([[-0.1742, -0.1283, -0.0753,  ...,  0.0885,  0.0831,  0.0367]]), '<dermatofibroma-class>': tensor([[ 0.0672,  0.0148, -0.1172,  ...,  0.1404, -0.1315,  0.0369]]), '<dermatomyositis-class>': tensor([[ 0.0116, -0.1472, -0.0664,  ..., -0.0748, -0.0432, -0.0111]]), '<eccrine_poroma-class>': tensor([[-0.0155,  0.0879,  0.0271,  ..., -0.0928, -0.0997, -0.0636]]), '<epidermal_cyst-class>': tensor([[ 0.0430, -0.0999, -0.1222,  ...,  0.1164, -0.0718,  0.0791]]), '<epidermal_nevus-class>': tensor([[ 0.1255, -0.1061,  0.1119,  ..., -0.0596,  0.0233,  0.0340]]), '<fibrous_papule-class>': tensor([[-0.0247,  0.0332,  0.1722,  ...,  0.1774,  0.0010, -0.0777]]), '<focal-acral-hyperkeratosis-class>': tensor([[-0.1995, -0.0488,  0.0131,  ...,  0.0347,  0.1539, -0.0124]]), '<folliculitis-class>': tensor([[-0.0820,  0.0003,  0.1555,  ..., -0.0148,  0.0183,  0.1118]]), '<foreign_body_granuloma-class>': tensor([[ 0.0361,  0.0434, -0.0464,  ...,  0.0433,  0.0660,  0.0391]]), '<glomangioma-class>': tensor([[-0.0685,  0.0302, -0.0133,  ...,  0.1224, -0.0756,  0.0404]]), '<graft-vs-host_disease-class>': tensor([[-0.0053, -0.0637,  0.0373,  ..., -0.0159, -0.0120, -0.0544]]), '<hematoma-class>': tensor([[-0.0426, -0.0140, -0.0071,  ...,  0.2240, -0.0162,  0.0460]]), '<hyperpigmentation-class>': tensor([[-0.2000, -0.0945, -0.0108,  ...,  0.1498,  0.1488, -0.0074]]), '<kaposi_sarcoma-class>': tensor([[ 0.0163,  0.1275, -0.0119,  ...,  0.1904, -0.0526, -0.0641]]), '<keloid-class>': tensor([[-0.1854, -0.0891,  0.0692,  ...,  0.0036,  0.1455, -0.1596]]), '<leukemia_cutis-class>': tensor([[ 0.0487,  0.0934,  0.0561,  ...,  0.0710, -0.0180,  0.1459]]), '<lichenoid_keratosis-class>': tensor([[ 0.1116, -0.2116, -0.1294,  ..., -0.0450, -0.0109, -0.0634]]), '<lipoma-class>': tensor([[ 0.1301, -0.0551,  0.0450,  ...,  0.0718, -0.0789,  0.3087]]), '<lymphocytic_infiltrations-class>': tensor([[-0.0362, -0.1745,  0.0643,  ...,  0.0766, -0.2850,  0.0209]]), '<melanoma-class>': tensor([[-0.0903, -0.2791,  0.1199,  ...,  0.1084, -0.2180, -0.1250]]), '<metastatic_carcinoma-class>': tensor([[ 0.1442, -0.0529,  0.1548,  ..., -0.0021, -0.0306,  0.0292]]), '<molluscum_contagiosum-class>': tensor([[-0.1018, -0.0870, -0.1516,  ...,  0.2135, -0.0437,  0.1229]]), '<neurofibroma-class>': tensor([[ 0.0416,  0.1094,  0.0982,  ..., -0.0803, -0.0413,  0.0952]]), '<neuroma-class>': tensor([[-0.0818, -0.0299, -0.0301,  ...,  0.0463, -0.0942, -0.0278]]), '<nevus-class>': tensor([[-0.2218, -0.0228,  0.3082,  ..., -0.0245,  0.0468,  0.0334]]), '<nevus_lipomatosus_superficialis-class>': tensor([[-0.0298, -0.1030,  0.1609,  ...,  0.0906, -0.0287, -0.0946]]), '<onychomycosis-class>': tensor([[-0.0496,  0.0089, -0.2315,  ..., -0.0333,  0.0323, -0.1543]]), '<prurigo_nodularis-class>': tensor([[ 0.3405,  0.1060, -0.0483,  ..., -0.0140,  0.1194,  0.2161]]), '<pyogenic_granuloma-class>': tensor([[-0.0121,  0.0978,  0.0631,  ..., -0.0122,  0.0330,  0.0452]]), '<reactive_lymphoid_hyperplasia-class>': tensor([[-0.0516, -0.1266, -0.2478,  ...,  0.2348, -0.0533,  0.0165]]), '<scar-class>': tensor([[-0.0247, -0.0882,  0.0396,  ...,  0.1157, -0.0162, -0.0561]]), '<sebaceous_carcinoma-class>': tensor([[-0.0897, -0.0788,  0.0967,  ...,  0.2163,  0.0456,  0.1438]]), '<seborrheic_keratosis-class>': tensor([[-0.1404, -0.0482,  0.1117,  ...,  0.0536, -0.0874, -0.0578]]), '<solar_lentigo-class>': tensor([[ 0.1050, -0.0331, -0.0240,  ...,  0.0162,  0.0561,  0.2875]]), '<spindle_cell_nevus_of_Reed-class>': tensor([[ 6.6210e-02,  1.4387e-04,  2.5708e-01,  ...,  7.2909e-02,\n",
            "         -9.7165e-03,  3.4696e-02]]), '<squamous_cell_carcinoma-class>': tensor([[-0.0656,  0.0406,  0.1537,  ...,  0.2397, -0.1223,  0.1160]]), '<syringocystadenoma_papilliferum-class>': tensor([[-0.0149,  0.0284,  0.0229,  ...,  0.0501, -0.1245,  0.0808]]), '<tinea_pedis-class>': tensor([[ 0.0860, -0.0303,  0.2233,  ..., -0.0934,  0.0862,  0.1068]]), '<traumatic_injury-class>': tensor([[-0.3167, -0.0854,  0.0013,  ..., -0.0747, -0.2545,  0.0116]]), '<trichilemmoma-class>': tensor([[-0.0873, -0.0879, -0.0294,  ..., -0.1299, -0.1599,  0.0324]]), '<trichofolliculoma-class>': tensor([[-0.1560,  0.0007,  0.0133,  ..., -0.0627,  0.0767, -0.1053]]), '<verruca_vulgaris-class>': tensor([[ 0.0599, -0.1204,  0.1126,  ...,  0.0068, -0.0763,  0.0598]]), '<verruciform_xanthoma-class>': tensor([[-0.0225, -0.0525,  0.0961,  ..., -0.0058, -0.0381, -0.0057]]), '<xanthogranuloma-class>': tensor([[ 0.0758, -0.1077, -0.0067,  ...,  0.0090,  0.1767, -0.0810]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "### if you want to use images of light skin only for training, comment out the last two parts in the concept list.\n",
        "def make_concepts_list(special_token, disease):\n",
        "    # instace_data_dir: specificaly the data for the disease (and I assume skin color)\n",
        "    # class_data_dir: the data for the skin color (anything else)?\n",
        "    base_instance = f'./' # the repo with your instance data (diseased data, DDI)\n",
        "    base_class = f'./' # the repo with your class data (healthy synthetics)\n",
        "    concepts_list = [\n",
        "        {\n",
        "            \"instance_prompt\":      f\"An image of {special_token} on the skin of a light-skinned individual\",\n",
        "            \"instance_data_dir\":    f\"{base_instance}/light/{disease}\", # 1 is Fitzpatrick scale for skin-tone\n",
        "            \"class_prompt\":         \"An image of healthy skin on a light-skinned individual\", # insert marker?\n",
        "            \"class_data_dir\":       f\"{base_class}/light/\",\n",
        "            \"label\":                0,\n",
        "        },\n",
        "        {\n",
        "            \"instance_prompt\":      f\"An image of {special_token} on the skin of a medium-skinned individual\",\n",
        "            \"instance_data_dir\":    f\"{base_instance}/medium/{disease}\", # 2 is Fitzpatrick scale for skin-tone\n",
        "            \"class_prompt\":         \"An image of healthy skin on a medium-skinned individual\", # insert ruler?\n",
        "            \"class_data_dir\":       f\"{base_class}/medium/\",\n",
        "            \"label\":                1,\n",
        "        },\n",
        "        {\n",
        "            \"instance_prompt\":      f\"An image of {special_token} on the skin of a dark-skinned individual\",\n",
        "            \"instance_data_dir\":    f\"{base_instance}/dark/{disease}\", # 5 is Fitz\n",
        "            \"class_prompt\":         \"An image of healthy skin on a dark-skinned individual\", # only ruler is easy\n",
        "            \"class_data_dir\":       f\"{base_class}/dark/\", # where that data lives?\n",
        "            \"label\":                2,\n",
        "\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    for c in concepts_list:\n",
        "        os.makedirs(c[\"instance_data_dir\"], exist_ok=True) # creates all above jsons\n",
        "\n",
        "    with open(f\"ti_lora_concepts_list_seed={SPLIT}_{SEED}.json\", \"w\") as f:\n",
        "        json.dump(concepts_list, f, indent=4)"
      ],
      "metadata": {
        "id": "O79QjEq0EdJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diseases = [\n",
        "    \"abscess\", \"acne-cystic\", \"acquired digital fibrokeratoma\", \"acral melanotic macule\",\n",
        "    \"acrochordon\", \"actinic keratosis\", \"angioleiomyoma\", \"angioma\",\n",
        "    \"arteriovenous hemangioma\", \"basal cell carcinoma\", \"benign keratosis\",\n",
        "    \"blastic plasmacytoid dendritic cell neoplasm\", \"blue nevus\", \"cellular neurothekeoma\",\n",
        "    \"chondroid syringoma\", \"clear cell acanthoma\", \"coccidioidomycosis\",\n",
        "    \"condyloma acuminatum\", \"cutaneous T-cell lymphoma\", \"dermatofibroma\",\n",
        "    \"dermatomyositis\", \"eccrine poroma\", \"eczema/atopic dermatitis\",\n",
        "    \"epidermal cyst\", \"epidermal nevus\", \"fibrous papule\", \"focal-acral-hyperkeratosis\",\n",
        "    \"folliculitis\", \"foreign body granuloma\", \"glomangioma\", \"graft-vs-host disease\",\n",
        "    \"hematoma\", \"hyperpigmentation\", \"kaposi sarcoma\", \"keloid\", \"leukemia cutis\",\n",
        "    \"lichenoid keratosis\", \"lipoma\", \"lymphocytic infiltrations\", \"melanoma\",\n",
        "    \"metastatic carcinoma\", \"molluscum contagiosum\", \"neurofibroma\", \"neuroma\", \"nevus\",\n",
        "    \"nevus lipomatosus superficialis\", \"onychomycosis\", \"prurigo nodularis\",\n",
        "    \"pyogenic granuloma\", \"reactive lymphoid hyperplasia\", \"scar\", \"scleroderma/morphea\",\n",
        "    \"sebaceous carcinoma\", \"seborrheic keratosis\", \"solar lentigo\", \"spindle cell nevus of Reed\",\n",
        "    \"squamous cell carcinoma\", \"syringocystadenoma papilliferum\", \"tinea pedis\",\n",
        "    \"traumatic injury\", \"trichilemmoma\", \"trichofolliculoma\", \"verruca vulgaris\",\n",
        "    \"verruciform xanthoma\", \"xanthogranuloma\"] # All diseases in DDI"
      ],
      "metadata": {
        "id": "wsWDVvuLum4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_disease = {}\n",
        "for disease in diseases:\n",
        "    # Replace spaces with underscores\n",
        "    safe_disease = disease.replace(\" \", \"_\")\n",
        "    # Construct the token\n",
        "    token = f\"<{safe_disease}-class>\"\n",
        "    # Populate the dictionary\n",
        "    token_to_disease[token] = disease"
      ],
      "metadata": {
        "id": "zTHD3aCcuk2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_disease"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6fbCVHznRTX",
        "outputId": "5bd97499-057d-479b-e1d6-0899c498815a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<abscess-class>': 'abscess',\n",
              " '<acne-cystic-class>': 'acne-cystic',\n",
              " '<acquired_digital_fibrokeratoma-class>': 'acquired digital fibrokeratoma',\n",
              " '<acral_melanotic_macule-class>': 'acral melanotic macule',\n",
              " '<acrochordon-class>': 'acrochordon',\n",
              " '<actinic_keratosis-class>': 'actinic keratosis',\n",
              " '<angioleiomyoma-class>': 'angioleiomyoma',\n",
              " '<angioma-class>': 'angioma',\n",
              " '<arteriovenous_hemangioma-class>': 'arteriovenous hemangioma',\n",
              " '<basal_cell_carcinoma-class>': 'basal cell carcinoma',\n",
              " '<benign_keratosis-class>': 'benign keratosis',\n",
              " '<blastic_plasmacytoid_dendritic_cell_neoplasm-class>': 'blastic plasmacytoid dendritic cell neoplasm',\n",
              " '<blue_nevus-class>': 'blue nevus',\n",
              " '<cellular_neurothekeoma-class>': 'cellular neurothekeoma',\n",
              " '<chondroid_syringoma-class>': 'chondroid syringoma',\n",
              " '<clear_cell_acanthoma-class>': 'clear cell acanthoma',\n",
              " '<coccidioidomycosis-class>': 'coccidioidomycosis',\n",
              " '<condyloma_acuminatum-class>': 'condyloma acuminatum',\n",
              " '<cutaneous_T-cell_lymphoma-class>': 'cutaneous T-cell lymphoma',\n",
              " '<dermatofibroma-class>': 'dermatofibroma',\n",
              " '<dermatomyositis-class>': 'dermatomyositis'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skin_types = {\n",
        "    'light': 'a light-skinned',\n",
        "    'medium': 'a medium-skinned',\n",
        "    'dark': 'a dark-skinned',\n",
        "}\n",
        "\n",
        "for token, disease in token_to_disease.items():\n",
        "    print(token, disease)\n",
        "    make_concepts_list(token, disease)\n",
        "    concept_list = f\"ti_lora_concepts_list_seed={SPLIT}_{SEED}.json\"\n",
        "\n",
        "    MODEL_NAME = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    OUTPUT_DIR = f\"./\"\n",
        "    embed_path = target_path\n",
        "\n",
        "    print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "    !accelerate launch train_lora.py \\\n",
        "        --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "        --output_dir=\"$OUTPUT_DIR\" \\\n",
        "        --revision=\"fp16\" \\\n",
        "        --seed=$SEED \\\n",
        "        --resolution=256 \\\n",
        "        --train_batch_size=16 \\\n",
        "        --with_prior_preservation \\\n",
        "        --num_class_images=96 \\\n",
        "        --sample_batch_size=16 \\\n",
        "        --mixed_precision=\"fp16\" \\\n",
        "        --use_8bit_adam \\\n",
        "        --gradient_accumulation_steps=1 \\\n",
        "        --gradient_checkpointing \\\n",
        "        --learning_rate=5e-6 \\\n",
        "        --lr_scheduler=\"constant\" \\\n",
        "        --lr_warmup_steps=0 \\\n",
        "        --max_train_steps=750 \\\n",
        "        --checkpointing_steps=250 \\\n",
        "        --concepts_list=$concept_list \\\n",
        "        --rank=8 \\\n",
        "        --embed_path=\"$embed_path\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A3QbxdpEjuc",
        "outputId": "bb9350a9-4b85-4200-babb-bee9541c2698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<abscess-class> abscess\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/abscess\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 21:09:52.002022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740258592.021856    4197 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740258592.027913    4197 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 21:09:52.047623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 21:09:54 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "tokenizer%2Ftokenizer_config.json: 100% 824/824 [00:00<00:00, 7.43MB/s]\n",
            "tokenizer%2Fvocab.json: 100% 1.06M/1.06M [00:00<00:00, 3.90MB/s]\n",
            "tokenizer%2Fmerges.txt: 100% 525k/525k [00:00<00:00, 2.16MB/s]\n",
            "tokenizer%2Fspecial_tokens_map.json: 100% 460/460 [00:00<00:00, 3.93MB/s]\n",
            "text_encoder%2Fconfig.json: 100% 633/633 [00:00<00:00, 6.44MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "scheduler%2Fscheduler_config.json: 100% 346/346 [00:00<00:00, 3.98MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'timestep_spacing', 'thresholding', 'clip_sample_range', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "pytorch_model.bin: 100% 681M/681M [00:01<00:00, 348MB/s]\n",
            "vae%2Fconfig.json: 100% 617/617 [00:00<00:00, 5.64MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "diffusion_pytorch_model.bin:  56% 94.4M/167M [00:00<00:00, 123MB/s]\n",
            "diffusion_pytorch_model.bin:  69% 115M/167M [00:01<00:00, 85.1MB/s]\n",
            "diffusion_pytorch_model.bin: 100% 167M/167M [00:01<00:00, 110MB/s]\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "model.safetensors:   5% 73.4M/1.36G [00:00<00:04, 275MB/s]\u001b[A/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "\n",
            "model.safetensors:   8% 105M/1.36G [00:00<00:04, 268MB/s] \u001b[A\n",
            "model.safetensors:  11% 147M/1.36G [00:00<00:04, 291MB/s]\u001b[A\n",
            "model.safetensors:  14% 189M/1.36G [00:00<00:03, 311MB/s]\u001b[A\n",
            "unet%2Fconfig.json: 100% 976/976 [00:00<00:00, 9.61MB/s]\n",
            "\n",
            "model.safetensors:  18% 252M/1.36G [00:00<00:03, 290MB/s]\u001b[A\n",
            "model.safetensors:  21% 283M/1.36G [00:00<00:03, 283MB/s]\u001b[A\n",
            "model.safetensors:  23% 315M/1.36G [00:01<00:03, 271MB/s]\u001b[A\n",
            "model.safetensors:  26% 357M/1.36G [00:01<00:03, 304MB/s]\u001b[A\n",
            "diffusion_pytorch_model.bin:   0% 0.00/1.73G [00:00<?, ?B/s]\n",
            "model.safetensors:  31% 419M/1.36G [00:01<00:03, 282MB/s]\u001b[A\n",
            "diffusion_pytorch_model.bin:   1% 10.5M/1.73G [00:00<00:33, 50.8MB/s]\n",
            "diffusion_pytorch_model.bin:   2% 41.9M/1.73G [00:00<00:10, 156MB/s] \n",
            "diffusion_pytorch_model.bin:   5% 83.9M/1.73G [00:00<00:06, 238MB/s]\n",
            "diffusion_pytorch_model.bin:   7% 126M/1.73G [00:00<00:05, 280MB/s] \n",
            "diffusion_pytorch_model.bin:  10% 168M/1.73G [00:00<00:05, 308MB/s]\n",
            "diffusion_pytorch_model.bin:  12% 210M/1.73G [00:00<00:04, 324MB/s]\n",
            "diffusion_pytorch_model.bin:  15% 252M/1.73G [00:00<00:04, 341MB/s]\n",
            "diffusion_pytorch_model.bin:  17% 294M/1.73G [00:01<00:04, 337MB/s]\n",
            "model.safetensors:  55% 755M/1.36G [00:02<00:01, 358MB/s]\u001b[A\n",
            "diffusion_pytorch_model.bin:  19% 336M/1.73G [00:01<00:04, 296MB/s]\n",
            "diffusion_pytorch_model.bin:  21% 367M/1.73G [00:01<00:05, 249MB/s]\n",
            "diffusion_pytorch_model.bin:  23% 398M/1.73G [00:01<00:05, 247MB/s]\n",
            "diffusion_pytorch_model.bin:  25% 430M/1.73G [00:01<00:04, 261MB/s]\n",
            "diffusion_pytorch_model.bin:  27% 461M/1.73G [00:01<00:04, 272MB/s]\n",
            "diffusion_pytorch_model.bin:  28% 493M/1.73G [00:01<00:04, 279MB/s]\n",
            "diffusion_pytorch_model.bin:  30% 524M/1.73G [00:02<00:05, 210MB/s]\n",
            "diffusion_pytorch_model.bin:  32% 556M/1.73G [00:02<00:05, 210MB/s]\n",
            "diffusion_pytorch_model.bin:  34% 587M/1.73G [00:03<00:16, 70.8MB/s]\n",
            "diffusion_pytorch_model.bin:  35% 608M/1.73G [00:04<00:26, 43.1MB/s]\n",
            "diffusion_pytorch_model.bin:  38% 650M/1.73G [00:04<00:16, 65.2MB/s]\n",
            "model.safetensors:  86% 1.17G/1.36G [00:06<00:02, 86.3MB/s]\u001b[A\n",
            "model.safetensors:  89% 1.22G/1.36G [00:06<00:01, 116MB/s] \u001b[A\n",
            "diffusion_pytorch_model.bin:  42% 734M/1.73G [00:05<00:09, 107MB/s] \n",
            "diffusion_pytorch_model.bin:  44% 765M/1.73G [00:05<00:07, 128MB/s]\n",
            "model.safetensors: 100% 1.36G/1.36G [00:06<00:00, 203MB/s]\n",
            "diffusion_pytorch_model.bin: 100% 1.73G/1.73G [00:09<00:00, 188MB/s]\n",
            "{'projection_class_embeddings_input_dim', 'cross_attention_norm', 'transformer_layers_per_block', 'mid_block_only_cross_attention', 'time_cond_proj_dim', 'class_embeddings_concat', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'addition_embed_type', 'dropout', 'time_embedding_act_fn', 'conv_out_kernel', 'upcast_attention', 'num_attention_heads', 'reverse_transformer_layers_per_block', 'mid_block_type', 'timestep_post_act', 'resnet_out_scale_factor', 'encoder_hid_dim_type', 'time_embedding_dim', 'conv_in_kernel', 'resnet_time_scale_shift', 'addition_time_embed_dim', 'attention_type', 'class_embed_type', 'time_embedding_type'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e8c210>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e8fd10>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e9b190>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e817d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb13d5ed0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbebcd3ec90>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e70cd0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e9bf50>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1ee5650>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1ee6110>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1efc8d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1efd390>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e80d90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0a49c90>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e99890>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0a61190>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e9a210>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0a74650>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0a77a90>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e8db10>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0a96f50>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbebcd3cdd0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0aae450>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0aaef10>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0ace3d0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0acee90>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0ae9890>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e21250>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0904d50>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb0905810>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e21190>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cbeb1e83610>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/abscess', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<acne-cystic-class> acne-cystic\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acne-cystic\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 21:12:32.734425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740258752.754199    4919 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740258752.760184    4919 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 21:12:32.779950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 21:12:35 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'variance_type', 'sample_max_value', 'clip_sample_range', 'thresholding', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'time_embedding_dim', 'cross_attention_norm', 'encoder_hid_dim_type', 'time_cond_proj_dim', 'upcast_attention', 'attention_type', 'addition_time_embed_dim', 'time_embedding_type', 'conv_out_kernel', 'class_embeddings_concat', 'dropout', 'time_embedding_act_fn', 'num_attention_heads', 'conv_in_kernel', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'mid_block_type', 'class_embed_type', 'addition_embed_type', 'resnet_skip_time_act', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'transformer_layers_per_block', 'resnet_time_scale_shift', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820bc5ed0>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c011d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820be1ad0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820be1410>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c03510>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820b27510>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c2b350>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c2bdd0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c47290>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c47d10>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820b964d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820b67410>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf81033ec10>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf81033f6d0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf810352110>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf810352bd0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf810369610>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820bea190>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103855d0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf810386090>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103acb10>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103ad5d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103afd90>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103c4ad0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103c7d90>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf820c28c50>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103db4d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8103dbfd0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8101f69d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf8101f7490>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf810307750>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7bf81031c250>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acne-cystic', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<acquired_digital_fibrokeratoma-class> acquired digital fibrokeratoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 21:14:57.944096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740258897.964056    5576 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740258897.970107    5576 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 21:14:57.990645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 21:15:00 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'sample_max_value', 'variance_type', 'timestep_spacing', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'resnet_skip_time_act', 'class_embed_type', 'addition_time_embed_dim', 'num_attention_heads', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'addition_embed_type', 'resnet_out_scale_factor', 'timestep_post_act', 'cross_attention_norm', 'dropout', 'conv_out_kernel', 'resnet_time_scale_shift', 'mid_block_only_cross_attention', 'projection_class_embeddings_input_dim', 'reverse_transformer_layers_per_block', 'conv_in_kernel', 'encoder_hid_dim_type', 'upcast_attention', 'time_cond_proj_dim', 'class_embeddings_concat', 'mid_block_type', 'encoder_hid_dim', 'attention_type', 'time_embedding_dim', 'transformer_layers_per_block', 'time_embedding_type'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47ee890>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47c9210>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47bf550>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47b7810>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47fc3d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47ff2d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e82e3d10>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f4e48550>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e82e8f50>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f4841910>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e82e3c90>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e8324850>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e836c6d0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e836d190>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07f47efa50>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e8384690>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e83870d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e8387b90>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e83a3010>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e83a3ad0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e83ba550>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e83bb010>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e81e5a50>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e81e6510>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e81fda50>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e81fe510>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e8214f90>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e8215a50>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e822c4d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e822cf90>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e833d190>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f07e833dc50>\n",
            "750\n",
            "02/22/2025 21:17:13 - INFO - __main__ - ***** Running training *****\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Num examples = 96\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Num instance images = 1\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Num Epochs = 125\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/22/2025 21:17:13 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [10:25<21:13,  2.55s/it, loss=0.492, lr=5e-6]02/22/2025 21:27:38 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/22/2025 21:27:38 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250/optimizer.bin\n",
            "02/22/2025 21:27:38 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250/scheduler.bin\n",
            "02/22/2025 21:27:38 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250/sampler.bin\n",
            "02/22/2025 21:27:38 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250/scaler.pt\n",
            "02/22/2025 21:27:38 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250/random_states_0.pkl\n",
            "02/22/2025 21:27:38 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-250\n",
            "Steps:  67% 500/750 [21:01<10:42,  2.57s/it, loss=0.264, lr=5e-6]02/22/2025 21:38:14 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/22/2025 21:38:14 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500/optimizer.bin\n",
            "02/22/2025 21:38:14 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500/scheduler.bin\n",
            "02/22/2025 21:38:14 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500/sampler.bin\n",
            "02/22/2025 21:38:14 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500/scaler.pt\n",
            "02/22/2025 21:38:14 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500/random_states_0.pkl\n",
            "02/22/2025 21:38:14 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-500\n",
            "Steps: 100% 750/750 [31:36<00:00,  2.44s/it, loss=0.268, lr=5e-6]02/22/2025 21:48:50 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/22/2025 21:48:50 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750/optimizer.bin\n",
            "02/22/2025 21:48:50 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750/scheduler.bin\n",
            "02/22/2025 21:48:50 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750/sampler.bin\n",
            "02/22/2025 21:48:50 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750/scaler.pt\n",
            "02/22/2025 21:48:50 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750/random_states_0.pkl\n",
            "02/22/2025 21:48:50 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/checkpoint-750\n",
            "Steps: 100% 750/750 [31:37<00:00,  2.44s/it, loss=0.233, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acquired digital fibrokeratoma/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [31:37<00:00,  2.53s/it, loss=0.233, lr=5e-6]\n",
            "<acral_melanotic_macule-class> acral melanotic macule\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acral melanotic macule\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 21:49:02.053068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740260942.072982   14278 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740260942.079079   14278 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 21:49:02.100122: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 21:49:04 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'sample_max_value', 'clip_sample_range', 'thresholding', 'variance_type', 'timestep_spacing', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'resnet_out_scale_factor', 'mid_block_type', 'class_embed_type', 'conv_out_kernel', 'dropout', 'time_embedding_type', 'transformer_layers_per_block', 'upcast_attention', 'num_attention_heads', 'resnet_time_scale_shift', 'addition_embed_type', 'time_embedding_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'time_cond_proj_dim', 'resnet_skip_time_act', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'conv_in_kernel', 'addition_time_embed_dim', 'encoder_hid_dim_type', 'attention_type', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'encoder_hid_dim', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1336876890>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368af290>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368873d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d133689ce10>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1336892390>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1336893d10>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368d2150>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368d2c10>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368f20d0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368f2b90>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1336839810>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1334009d90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1334055b50>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13368ae810>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d133406d050>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d133406db10>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1334084590>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1334085050>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13367e4550>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13367e7ed0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d133409f990>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340c0490>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340c2ed0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340c3990>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340daed0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340db990>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340f2410>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340f2ed0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1328301950>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1328302410>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d13340265d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1334027090>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acral melanotic macule', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<acrochordon-class> acrochordon\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 21:51:25.332269: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740261085.352075   14900 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740261085.358083   14900 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 21:51:25.378006: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 21:51:27 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type', 'timestep_spacing', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'encoder_hid_dim_type', 'time_embedding_act_fn', 'dropout', 'resnet_out_scale_factor', 'cross_attention_norm', 'mid_block_type', 'reverse_transformer_layers_per_block', 'class_embed_type', 'encoder_hid_dim', 'resnet_skip_time_act', 'attention_type', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'addition_embed_type', 'resnet_time_scale_shift', 'conv_out_kernel', 'upcast_attention', 'time_embedding_type', 'addition_time_embed_dim', 'time_embedding_dim', 'time_cond_proj_dim', 'class_embeddings_concat', 'num_attention_heads', 'transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'timestep_post_act'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0e92d0>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0f7d50>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c105810>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0dfa90>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0d1590>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0d24d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c106990>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c127010>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c14e4d0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c14ef90>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c165750>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c166210>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c1b6010>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c1b6ad0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d20305510>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c105e50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c104c10>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2031d490>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d20334910>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d203353d0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d20337d90>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d203588d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2035b290>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0e3d10>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d203731d0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0ebd90>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2038a690>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0eb0d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2039db10>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2039e5d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c182b10>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d7d2c0e3450>\n",
            "750\n",
            "02/22/2025 21:53:30 - INFO - __main__ - ***** Running training *****\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Num examples = 96\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Num instance images = 17\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Num Epochs = 125\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/22/2025 21:53:30 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [11:11<22:13,  2.67s/it, loss=0.554, lr=5e-6]02/22/2025 22:04:42 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/22/2025 22:04:42 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250/optimizer.bin\n",
            "02/22/2025 22:04:42 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250/scheduler.bin\n",
            "02/22/2025 22:04:42 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250/sampler.bin\n",
            "02/22/2025 22:04:42 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250/scaler.pt\n",
            "02/22/2025 22:04:42 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250/random_states_0.pkl\n",
            "02/22/2025 22:04:42 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-250\n",
            "Steps:  67% 500/750 [22:14<11:09,  2.68s/it, loss=0.292, lr=5e-6]02/22/2025 22:15:45 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/22/2025 22:15:45 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500/optimizer.bin\n",
            "02/22/2025 22:15:45 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500/scheduler.bin\n",
            "02/22/2025 22:15:45 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500/sampler.bin\n",
            "02/22/2025 22:15:45 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500/scaler.pt\n",
            "02/22/2025 22:15:45 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500/random_states_0.pkl\n",
            "02/22/2025 22:15:45 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-500\n",
            "Steps: 100% 750/750 [33:15<00:00,  2.51s/it, loss=0.288, lr=5e-6]02/22/2025 22:26:45 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/22/2025 22:26:46 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750/optimizer.bin\n",
            "02/22/2025 22:26:46 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750/scheduler.bin\n",
            "02/22/2025 22:26:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750/sampler.bin\n",
            "02/22/2025 22:26:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750/scaler.pt\n",
            "02/22/2025 22:26:46 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750/random_states_0.pkl\n",
            "02/22/2025 22:26:46 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/checkpoint-750\n",
            "Steps: 100% 750/750 [33:15<00:00,  2.51s/it, loss=0.259, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/acrochordon/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [33:15<00:00,  2.66s/it, loss=0.259, lr=5e-6]\n",
            "<actinic_keratosis-class> actinic keratosis\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 22:26:58.295580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740263218.319198   23811 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740263218.326419   23811 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 22:26:58.350104: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 22:27:01 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'sample_max_value', 'dynamic_thresholding_ratio', 'clip_sample_range', 'variance_type', 'timestep_spacing', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'time_embedding_act_fn', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'mid_block_only_cross_attention', 'cross_attention_norm', 'resnet_skip_time_act', 'mid_block_type', 'conv_out_kernel', 'dropout', 'attention_type', 'time_embedding_dim', 'addition_embed_type_num_heads', 'addition_embed_type', 'time_embedding_type', 'encoder_hid_dim', 'upcast_attention', 'transformer_layers_per_block', 'encoder_hid_dim_type', 'addition_time_embed_dim', 'class_embeddings_concat', 'num_attention_heads', 'class_embed_type', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'reverse_transformer_layers_per_block', 'resnet_out_scale_factor', 'timestep_post_act'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835af7d10>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c2d8d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c23e90>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c21f90>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c30310>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c517d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c851d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c85c90>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828305110>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828305bd0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c50790>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c50fd0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c40a90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828361610>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828363fd0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc82837cb10>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc82837f550>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc82837ffd0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828397510>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828397d90>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c52c10>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc8283b3490>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c320d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc8283da910>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc8283f1e10>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c12950>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c51450>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c521d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c30b90>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c313d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc835c51690>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7dc828332210>\n",
            "750\n",
            "02/22/2025 22:29:08 - INFO - __main__ - ***** Running training *****\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Num examples = 96\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Num instance images = 3\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Num Epochs = 125\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/22/2025 22:29:08 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [10:50<21:44,  2.61s/it, loss=0.524, lr=5e-6]02/22/2025 22:39:59 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/22/2025 22:39:59 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250/optimizer.bin\n",
            "02/22/2025 22:39:59 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250/scheduler.bin\n",
            "02/22/2025 22:39:59 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250/sampler.bin\n",
            "02/22/2025 22:39:59 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250/scaler.pt\n",
            "02/22/2025 22:39:59 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250/random_states_0.pkl\n",
            "02/22/2025 22:39:59 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-250\n",
            "Steps:  67% 500/750 [21:43<10:58,  2.63s/it, loss=0.299, lr=5e-6]02/22/2025 22:50:52 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/22/2025 22:50:52 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500/optimizer.bin\n",
            "02/22/2025 22:50:52 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500/scheduler.bin\n",
            "02/22/2025 22:50:52 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500/sampler.bin\n",
            "02/22/2025 22:50:52 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500/scaler.pt\n",
            "02/22/2025 22:50:52 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500/random_states_0.pkl\n",
            "02/22/2025 22:50:52 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-500\n",
            "Steps: 100% 750/750 [32:35<00:00,  2.52s/it, loss=0.294, lr=5e-6]02/22/2025 23:01:43 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/22/2025 23:01:44 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750/optimizer.bin\n",
            "02/22/2025 23:01:44 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750/scheduler.bin\n",
            "02/22/2025 23:01:44 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750/sampler.bin\n",
            "02/22/2025 23:01:44 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750/scaler.pt\n",
            "02/22/2025 23:01:44 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750/random_states_0.pkl\n",
            "02/22/2025 23:01:44 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/checkpoint-750\n",
            "Steps: 100% 750/750 [32:35<00:00,  2.52s/it, loss=0.266, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/actinic keratosis/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [32:35<00:00,  2.61s/it, loss=0.266, lr=5e-6]\n",
            "<angioleiomyoma-class> angioleiomyoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioleiomyoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 23:01:56.299533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740265316.323679   32637 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740265316.330970   32637 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 23:01:56.355650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 23:01:59 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'sample_max_value', 'timestep_spacing', 'clip_sample_range', 'thresholding', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'timestep_post_act', 'addition_time_embed_dim', 'mid_block_type', 'class_embed_type', 'dropout', 'class_embeddings_concat', 'num_attention_heads', 'resnet_skip_time_act', 'conv_out_kernel', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'time_cond_proj_dim', 'transformer_layers_per_block', 'upcast_attention', 'conv_in_kernel', 'encoder_hid_dim', 'addition_embed_type', 'resnet_out_scale_factor', 'time_embedding_type', 'cross_attention_norm', 'attention_type', 'mid_block_only_cross_attention', 'addition_embed_type_num_heads', 'encoder_hid_dim_type', 'projection_class_embeddings_input_dim', 'time_embedding_dim', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610826d250>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6108258150>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610824e810>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610826cc90>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6108260f10>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db2ad0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610826d110>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61082bdb90>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61082d4f50>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109d27310>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61082e81d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61082a0ed0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db2610>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db27d0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db1350>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6108260690>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610827b250>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db1550>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db1c90>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61082214d0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610818a510>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c610818afd0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61081ada10>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61081ae4d0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db3310>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6114448950>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db20d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c61081d9910>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6108260490>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db2390>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db39d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7c6109db0c50>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioleiomyoma', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<angioma-class> angioma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 23:04:20.153279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740265460.173247   33267 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740265460.179411   33267 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 23:04:20.200033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 23:04:22 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'clip_sample_range', 'thresholding', 'sample_max_value', 'timestep_spacing', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'resnet_out_scale_factor', 'time_embedding_act_fn', 'transformer_layers_per_block', 'resnet_time_scale_shift', 'resnet_skip_time_act', 'projection_class_embeddings_input_dim', 'mid_block_type', 'encoder_hid_dim_type', 'upcast_attention', 'conv_in_kernel', 'addition_time_embed_dim', 'encoder_hid_dim', 'class_embed_type', 'time_embedding_type', 'time_cond_proj_dim', 'class_embeddings_concat', 'conv_out_kernel', 'mid_block_only_cross_attention', 'cross_attention_norm', 'timestep_post_act', 'addition_embed_type_num_heads', 'dropout', 'num_attention_heads', 'reverse_transformer_layers_per_block', 'addition_embed_type', 'time_embedding_dim', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de54d50>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de45850>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de45b50>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14ddec5d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de2ab50>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de29250>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de310d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de7a3d0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c1a1990>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c1a2450>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c1b4c50>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de3d850>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14dd89890>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c201ed0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14fce0950>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c219350>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c21bd50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de30990>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c233cd0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c24c7d0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c24f210>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14de57d50>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c2726d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c273190>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c28e610>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c28f0d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c0a9b50>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c0aa610>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c0c1090>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c0c1b50>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c1d2090>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79b14c1d2b50>\n",
            "750\n",
            "02/22/2025 23:06:29 - INFO - __main__ - ***** Running training *****\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Num examples = 96\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Num instance images = 9\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Num Epochs = 125\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/22/2025 23:06:29 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [11:02<22:15,  2.67s/it, loss=0.509, lr=5e-6]02/22/2025 23:17:32 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/22/2025 23:17:32 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250/optimizer.bin\n",
            "02/22/2025 23:17:32 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250/scheduler.bin\n",
            "02/22/2025 23:17:32 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250/sampler.bin\n",
            "02/22/2025 23:17:32 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250/scaler.pt\n",
            "02/22/2025 23:17:32 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250/random_states_0.pkl\n",
            "02/22/2025 23:17:32 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-250\n",
            "Steps:  67% 500/750 [22:07<11:11,  2.69s/it, loss=0.278, lr=5e-6]02/22/2025 23:28:37 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/22/2025 23:28:37 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500/optimizer.bin\n",
            "02/22/2025 23:28:37 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500/scheduler.bin\n",
            "02/22/2025 23:28:37 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500/sampler.bin\n",
            "02/22/2025 23:28:37 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500/scaler.pt\n",
            "02/22/2025 23:28:37 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500/random_states_0.pkl\n",
            "02/22/2025 23:28:37 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-500\n",
            "Steps: 100% 750/750 [33:12<00:00,  2.52s/it, loss=0.28, lr=5e-6]02/22/2025 23:39:42 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/22/2025 23:39:43 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750/optimizer.bin\n",
            "02/22/2025 23:39:43 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750/scheduler.bin\n",
            "02/22/2025 23:39:43 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750/sampler.bin\n",
            "02/22/2025 23:39:43 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750/scaler.pt\n",
            "02/22/2025 23:39:43 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750/random_states_0.pkl\n",
            "02/22/2025 23:39:43 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/checkpoint-750\n",
            "Steps: 100% 750/750 [33:13<00:00,  2.52s/it, loss=0.243, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/angioma/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [33:13<00:00,  2.66s/it, loss=0.243, lr=5e-6]\n",
            "<arteriovenous_hemangioma-class> arteriovenous hemangioma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-22 23:39:54.880836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740267594.901543   42090 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740267594.907724   42090 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-22 23:39:54.929073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/22/2025 23:39:57 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'sample_max_value', 'dynamic_thresholding_ratio', 'variance_type', 'timestep_spacing', 'thresholding', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'time_cond_proj_dim', 'resnet_time_scale_shift', 'encoder_hid_dim_type', 'reverse_transformer_layers_per_block', 'resnet_skip_time_act', 'attention_type', 'projection_class_embeddings_input_dim', 'mid_block_only_cross_attention', 'transformer_layers_per_block', 'addition_time_embed_dim', 'class_embed_type', 'time_embedding_type', 'addition_embed_type_num_heads', 'dropout', 'addition_embed_type', 'class_embeddings_concat', 'timestep_post_act', 'conv_out_kernel', 'num_attention_heads', 'cross_attention_norm', 'upcast_attention', 'time_embedding_act_fn', 'encoder_hid_dim', 'time_embedding_dim', 'conv_in_kernel', 'resnet_out_scale_factor', 'mid_block_type'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601ab01d0>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601ace810>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601ab2b50>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601a9bb50>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601acd810>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb60da4b410>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601abd450>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601aedfd0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601ab1690>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600221ed0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600230690>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600231150>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600278e90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600279950>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600294390>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601abcf50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600297810>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb6002ac310>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb6002af7d0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb601aec3d0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb60da1d250>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb6002c7790>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb6002ee1d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb6002eec90>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600106190>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600106c50>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb60011d6d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb60011e190>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb600134c10>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb6001356d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb60024da50>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7cb60024e510>\n",
            "750\n",
            "02/22/2025 23:42:03 - INFO - __main__ - ***** Running training *****\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Num examples = 96\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Num instance images = 2\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Num Epochs = 125\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/22/2025 23:42:03 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [11:03<22:20,  2.68s/it, loss=0.532, lr=5e-6]02/22/2025 23:53:07 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/22/2025 23:53:07 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250/optimizer.bin\n",
            "02/22/2025 23:53:07 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250/scheduler.bin\n",
            "02/22/2025 23:53:07 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250/sampler.bin\n",
            "02/22/2025 23:53:07 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250/scaler.pt\n",
            "02/22/2025 23:53:07 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250/random_states_0.pkl\n",
            "02/22/2025 23:53:07 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-250\n",
            "Steps:  67% 500/750 [22:09<11:18,  2.71s/it, loss=0.295, lr=5e-6]02/23/2025 00:04:13 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 00:04:13 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500/optimizer.bin\n",
            "02/23/2025 00:04:13 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500/scheduler.bin\n",
            "02/23/2025 00:04:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500/sampler.bin\n",
            "02/23/2025 00:04:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500/scaler.pt\n",
            "02/23/2025 00:04:13 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 00:04:13 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-500\n",
            "Steps: 100% 750/750 [33:15<00:00,  2.52s/it, loss=0.272, lr=5e-6]02/23/2025 00:15:19 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 00:15:19 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750/optimizer.bin\n",
            "02/23/2025 00:15:19 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750/scheduler.bin\n",
            "02/23/2025 00:15:19 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750/sampler.bin\n",
            "02/23/2025 00:15:19 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750/scaler.pt\n",
            "02/23/2025 00:15:19 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 00:15:19 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/checkpoint-750\n",
            "Steps: 100% 750/750 [33:16<00:00,  2.52s/it, loss=0.26, lr=5e-6] Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/arteriovenous hemangioma/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [33:16<00:00,  2.66s/it, loss=0.26, lr=5e-6]\n",
            "<basal_cell_carcinoma-class> basal cell carcinoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 00:15:31.541105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740269731.561331   50869 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740269731.567581   50869 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 00:15:31.588084: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 00:15:34 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'timestep_spacing', 'thresholding', 'sample_max_value', 'variance_type', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'num_attention_heads', 'addition_time_embed_dim', 'encoder_hid_dim', 'conv_in_kernel', 'resnet_out_scale_factor', 'timestep_post_act', 'class_embeddings_concat', 'time_embedding_type', 'addition_embed_type', 'projection_class_embeddings_input_dim', 'upcast_attention', 'time_embedding_dim', 'time_embedding_act_fn', 'addition_embed_type_num_heads', 'class_embed_type', 'reverse_transformer_layers_per_block', 'encoder_hid_dim_type', 'time_cond_proj_dim', 'conv_out_kernel', 'resnet_time_scale_shift', 'mid_block_only_cross_attention', 'resnet_skip_time_act', 'transformer_layers_per_block', 'mid_block_type', 'cross_attention_norm', 'attention_type', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac96041cb50>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac96041e390>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9502fc9d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac96040ab50>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac960402b10>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac960400c10>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9603c9ad0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac960413dd0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9502fc510>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9502fce50>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9502ff790>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95032fe90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95037f110>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95037fbd0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac950392610>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9503930d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9503a9b50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9503aa610>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9503c9a50>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9503ca510>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9501f4fd0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac9501f5a90>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95020c510>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95020cfd0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac950220490>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac950220f50>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac950223990>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac950238490>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95023aed0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95023b990>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95035c690>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ac95035d150>\n",
            "750\n",
            "02/23/2025 00:17:39 - INFO - __main__ - ***** Running training *****\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Num examples = 96\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Num instance images = 44\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Num Epochs = 125\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/23/2025 00:17:39 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [11:34<22:21,  2.68s/it, loss=0.579, lr=5e-6]02/23/2025 00:29:13 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/23/2025 00:29:13 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250/optimizer.bin\n",
            "02/23/2025 00:29:13 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250/scheduler.bin\n",
            "02/23/2025 00:29:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250/sampler.bin\n",
            "02/23/2025 00:29:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250/scaler.pt\n",
            "02/23/2025 00:29:13 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250/random_states_0.pkl\n",
            "02/23/2025 00:29:13 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-250\n",
            "Steps:  67% 500/750 [22:36<11:06,  2.66s/it, loss=0.305, lr=5e-6]02/23/2025 00:40:15 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 00:40:15 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500/optimizer.bin\n",
            "02/23/2025 00:40:15 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500/scheduler.bin\n",
            "02/23/2025 00:40:15 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500/sampler.bin\n",
            "02/23/2025 00:40:15 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500/scaler.pt\n",
            "02/23/2025 00:40:15 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 00:40:15 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-500\n",
            "Steps: 100% 750/750 [33:35<00:00,  2.54s/it, loss=0.304, lr=5e-6]02/23/2025 00:51:14 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 00:51:14 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750/optimizer.bin\n",
            "02/23/2025 00:51:14 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750/scheduler.bin\n",
            "02/23/2025 00:51:14 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750/sampler.bin\n",
            "02/23/2025 00:51:14 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750/scaler.pt\n",
            "02/23/2025 00:51:14 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 00:51:14 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/checkpoint-750\n",
            "Steps: 100% 750/750 [33:35<00:00,  2.54s/it, loss=0.279, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/basal cell carcinoma/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [33:35<00:00,  2.69s/it, loss=0.279, lr=5e-6]\n",
            "<benign_keratosis-class> benign keratosis\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 00:51:26.825929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740271886.846488   59720 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740271886.852572   59720 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 00:51:26.873036: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 00:51:29 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'variance_type', 'dynamic_thresholding_ratio', 'sample_max_value', 'timestep_spacing', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'cross_attention_norm', 'num_attention_heads', 'time_embedding_act_fn', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'time_cond_proj_dim', 'attention_type', 'addition_time_embed_dim', 'addition_embed_type_num_heads', 'timestep_post_act', 'transformer_layers_per_block', 'conv_out_kernel', 'resnet_time_scale_shift', 'resnet_out_scale_factor', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'dropout', 'time_embedding_dim', 'class_embeddings_concat', 'mid_block_type', 'upcast_attention', 'mid_block_only_cross_attention', 'encoder_hid_dim_type', 'class_embed_type', 'addition_embed_type', 'time_embedding_type', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468318210>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468303950>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce46830a6d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468309c10>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce469bf16d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce469bf3050>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce469bf7090>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce469bf6a10>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468369590>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce469bb0f10>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce46837c7d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce4683454d0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce4683c8ed0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce4683c9990>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce4683e4390>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468344fd0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce4683e7810>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468200310>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468203790>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce469bb2890>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce46821ac90>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce46831b6d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468242150>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468242c10>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468256090>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468256b50>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce4682715d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468272090>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468344b10>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468285590>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce468399c90>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ce46839a750>\n",
            "750\n",
            "02/23/2025 00:53:37 - INFO - __main__ - ***** Running training *****\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Num examples = 96\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Num instance images = 7\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Num Epochs = 125\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/23/2025 00:53:37 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [10:49<21:53,  2.63s/it, loss=0.536, lr=5e-6]02/23/2025 01:04:26 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/23/2025 01:04:26 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250/optimizer.bin\n",
            "02/23/2025 01:04:26 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250/scheduler.bin\n",
            "02/23/2025 01:04:26 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250/sampler.bin\n",
            "02/23/2025 01:04:26 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250/scaler.pt\n",
            "02/23/2025 01:04:26 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250/random_states_0.pkl\n",
            "02/23/2025 01:04:26 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-250\n",
            "Steps:  67% 500/750 [21:38<10:53,  2.61s/it, loss=0.325, lr=5e-6]02/23/2025 01:15:15 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 01:15:15 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500/optimizer.bin\n",
            "02/23/2025 01:15:15 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500/scheduler.bin\n",
            "02/23/2025 01:15:15 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500/sampler.bin\n",
            "02/23/2025 01:15:15 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500/scaler.pt\n",
            "02/23/2025 01:15:15 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 01:15:15 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-500\n",
            "Steps: 100% 750/750 [32:26<00:00,  2.48s/it, loss=0.293, lr=5e-6]02/23/2025 01:26:03 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 01:26:04 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750/optimizer.bin\n",
            "02/23/2025 01:26:04 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750/scheduler.bin\n",
            "02/23/2025 01:26:04 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750/sampler.bin\n",
            "02/23/2025 01:26:04 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750/scaler.pt\n",
            "02/23/2025 01:26:04 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 01:26:04 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/checkpoint-750\n",
            "Steps: 100% 750/750 [32:27<00:00,  2.48s/it, loss=0.261, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/benign keratosis/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [32:27<00:00,  2.60s/it, loss=0.261, lr=5e-6]\n",
            "<blastic_plasmacytoid_dendritic_cell_neoplasm-class> blastic plasmacytoid dendritic cell neoplasm\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blastic plasmacytoid dendritic cell neoplasm\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 01:26:15.919008: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740273975.938945   68314 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740273975.945005   68314 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 01:26:15.965385: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 01:26:18 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'variance_type', 'clip_sample_range', 'sample_max_value', 'thresholding', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'upcast_attention', 'addition_embed_type', 'class_embed_type', 'mid_block_only_cross_attention', 'projection_class_embeddings_input_dim', 'attention_type', 'time_embedding_type', 'class_embeddings_concat', 'timestep_post_act', 'dropout', 'time_embedding_act_fn', 'conv_in_kernel', 'conv_out_kernel', 'reverse_transformer_layers_per_block', 'transformer_layers_per_block', 'mid_block_type', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_out_scale_factor', 'resnet_skip_time_act', 'encoder_hid_dim', 'num_attention_heads', 'addition_time_embed_dim', 'cross_attention_norm', 'addition_embed_type_num_heads'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15287e7dd0>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15288ac550>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1528881a10>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1529799bd0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d152889f290>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d152889e810>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1528891490>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c2f9d50>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15287e7ad0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c32dc50>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15288905d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c340ed0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c2f4e90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c2f5710>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c38ff10>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15287e6550>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15286edb10>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1528ecd190>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c2f7490>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1528ecd350>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c1e2750>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c1e3210>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c205c10>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c2066d0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1528891b10>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c21a590>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c231010>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c231ad0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d152889c650>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d15287e7c90>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d151c359750>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d1528840b10>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blastic plasmacytoid dendritic cell neoplasm', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<blue_nevus-class> blue nevus\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 01:28:39.638476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740274119.658055   68934 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740274119.664172   68934 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 01:28:39.684225: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 01:28:42 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'clip_sample_range', 'variance_type', 'sample_max_value', 'timestep_spacing', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'addition_time_embed_dim', 'time_embedding_type', 'time_cond_proj_dim', 'time_embedding_dim', 'time_embedding_act_fn', 'conv_in_kernel', 'encoder_hid_dim_type', 'dropout', 'projection_class_embeddings_input_dim', 'num_attention_heads', 'addition_embed_type', 'cross_attention_norm', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'resnet_out_scale_factor', 'timestep_post_act', 'resnet_time_scale_shift', 'mid_block_type', 'transformer_layers_per_block', 'resnet_skip_time_act', 'class_embeddings_concat', 'class_embed_type', 'encoder_hid_dim', 'attention_type', 'reverse_transformer_layers_per_block', 'upcast_attention', 'conv_out_kernel'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540fed90>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540f2910>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0456937090>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540ff090>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540de0d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540dffd0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454127810>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454144310>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454147710>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454124410>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b045884ed50>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540df7d0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04541ab2d0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04541abd50>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04541be7d0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540ff390>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540f18d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0448312710>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b044832dbd0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b044832e690>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540e9250>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540ea010>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540f0210>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0448369050>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454124510>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04541253d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b045884d210>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0456936dd0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0448396dd0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b04540ffad0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454177cd0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7b0454188810>\n",
            "750\n",
            "02/23/2025 01:30:51 - INFO - __main__ - ***** Running training *****\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Num examples = 96\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Num instance images = 5\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Num Epochs = 125\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/23/2025 01:30:51 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [10:57<22:10,  2.66s/it, loss=0.535, lr=5e-6]02/23/2025 01:41:49 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/23/2025 01:41:49 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250/optimizer.bin\n",
            "02/23/2025 01:41:49 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250/scheduler.bin\n",
            "02/23/2025 01:41:49 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250/sampler.bin\n",
            "02/23/2025 01:41:49 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250/scaler.pt\n",
            "02/23/2025 01:41:50 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250/random_states_0.pkl\n",
            "02/23/2025 01:41:50 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-250\n",
            "Steps:  67% 500/750 [22:01<11:09,  2.68s/it, loss=0.301, lr=5e-6]02/23/2025 01:52:53 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 01:52:53 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500/optimizer.bin\n",
            "02/23/2025 01:52:53 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500/scheduler.bin\n",
            "02/23/2025 01:52:53 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500/sampler.bin\n",
            "02/23/2025 01:52:53 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500/scaler.pt\n",
            "02/23/2025 01:52:54 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 01:52:54 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-500\n",
            "Steps: 100% 750/750 [33:04<00:00,  2.52s/it, loss=0.283, lr=5e-6]02/23/2025 02:03:55 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 02:03:56 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750/optimizer.bin\n",
            "02/23/2025 02:03:56 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750/scheduler.bin\n",
            "02/23/2025 02:03:56 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750/sampler.bin\n",
            "02/23/2025 02:03:56 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750/scaler.pt\n",
            "02/23/2025 02:03:56 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 02:03:56 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/checkpoint-750\n",
            "Steps: 100% 750/750 [33:04<00:00,  2.52s/it, loss=0.265, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/blue nevus/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [33:04<00:00,  2.65s/it, loss=0.265, lr=5e-6]\n",
            "<cellular_neurothekeoma-class> cellular neurothekeoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cellular neurothekeoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 02:04:08.155073: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740276248.175372   77678 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740276248.181451   77678 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 02:04:08.202602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 02:04:10 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'sample_max_value', 'thresholding', 'timestep_spacing', 'dynamic_thresholding_ratio', 'clip_sample_range', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'attention_type', 'class_embed_type', 'conv_out_kernel', 'time_embedding_dim', 'class_embeddings_concat', 'num_attention_heads', 'dropout', 'addition_embed_type', 'resnet_out_scale_factor', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'conv_in_kernel', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'time_cond_proj_dim', 'addition_time_embed_dim', 'timestep_post_act', 'transformer_layers_per_block', 'encoder_hid_dim_type', 'projection_class_embeddings_input_dim', 'mid_block_type', 'reverse_transformer_layers_per_block', 'time_embedding_type', 'upcast_attention', 'cross_attention_norm', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a887c310>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a882b3d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c307690>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a88775d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a8863d50>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a8814490>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a8851050>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7918a8851f90>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c30add0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c30b890>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c342090>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c342b50>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c38e750>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c38f210>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c3a1b10>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c3a25d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c3bd050>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c3bdb10>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c1e0fd0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c1e1a90>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c304750>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c1fd1d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c1ff8d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c2183d0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c21b810>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c230310>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c232d10>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c2337d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c306090>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c246c50>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c35f290>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79189c35fd10>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cellular neurothekeoma', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<chondroid_syringoma-class> chondroid syringoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/chondroid syringoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 02:06:44.641985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740276404.661886   78354 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740276404.668097   78354 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 02:06:44.688996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 02:06:47 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value', 'thresholding', 'variance_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'mid_block_only_cross_attention', 'attention_type', 'time_embedding_act_fn', 'mid_block_type', 'time_cond_proj_dim', 'resnet_skip_time_act', 'resnet_out_scale_factor', 'class_embed_type', 'reverse_transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'encoder_hid_dim', 'dropout', 'addition_embed_type', 'transformer_layers_per_block', 'resnet_time_scale_shift', 'upcast_attention', 'addition_embed_type_num_heads', 'time_embedding_type', 'timestep_post_act', 'encoder_hid_dim_type', 'conv_in_kernel', 'addition_time_embed_dim', 'conv_out_kernel', 'num_attention_heads', 'class_embeddings_concat', 'time_embedding_dim', 'cross_attention_norm'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e939310>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e938990>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e89b690>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e89b2d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e949050>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e89b8d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e98b0d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e98bb90>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e95f350>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c0afa90>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c0c6290>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c0c6d50>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c10ecd0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c10f790>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c1221d0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c122c90>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e9492d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c13a110>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e949390>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c159f10>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c1789d0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c179490>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c17be90>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad5202fc950>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad5202ffd50>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad520314890>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad5203172d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad520317d50>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52032e810>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52032f2d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52e95f890>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7ad52c0dffd0>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/chondroid syringoma', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<clear_cell_acanthoma-class> clear cell acanthoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/clear cell acanthoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 02:09:32.204389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740276572.226027   79072 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740276572.232881   79072 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 02:09:32.254361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 02:09:35 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'timestep_spacing', 'sample_max_value', 'clip_sample_range', 'dynamic_thresholding_ratio', 'thresholding', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'resnet_time_scale_shift', 'encoder_hid_dim', 'transformer_layers_per_block', 'encoder_hid_dim_type', 'time_embedding_type', 'attention_type', 'mid_block_only_cross_attention', 'class_embeddings_concat', 'resnet_out_scale_factor', 'conv_in_kernel', 'num_attention_heads', 'time_embedding_dim', 'class_embed_type', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'dropout', 'mid_block_type', 'addition_embed_type', 'upcast_attention', 'projection_class_embeddings_input_dim', 'reverse_transformer_layers_per_block', 'cross_attention_norm', 'timestep_post_act', 'time_cond_proj_dim', 'conv_out_kernel', 'addition_time_embed_dim', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c355390>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c33ae90>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c34cc10>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c34fe50>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c365b10>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c365550>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c386210>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c386cd0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c3ae110>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c3aebd0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e201f13d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e201f1e90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c355e50>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c356bd0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e20255190>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e20255c50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c354890>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2026d150>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e202885d0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c329190>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2028bad0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e202ac5d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e202aefd0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e202afa90>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e202c6f50>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e202c7a10>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e200e2490>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c32b410>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2c365890>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e200f6410>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2020a8d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7d8e2020b390>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/clear cell acanthoma', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<coccidioidomycosis-class> coccidioidomycosis\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/coccidioidomycosis\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 02:12:13.365438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740276733.386095   79769 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740276733.392859   79769 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 02:12:13.414881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 02:12:16 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'timestep_spacing', 'thresholding', 'clip_sample_range', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'time_embedding_act_fn', 'encoder_hid_dim_type', 'class_embeddings_concat', 'num_attention_heads', 'dropout', 'reverse_transformer_layers_per_block', 'addition_embed_type', 'mid_block_type', 'timestep_post_act', 'time_embedding_type', 'addition_embed_type_num_heads', 'addition_time_embed_dim', 'encoder_hid_dim', 'upcast_attention', 'resnet_out_scale_factor', 'conv_out_kernel', 'resnet_skip_time_act', 'resnet_time_scale_shift', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'class_embed_type', 'mid_block_only_cross_attention', 'time_cond_proj_dim', 'attention_type', 'cross_attention_norm', 'time_embedding_dim', 'transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a107046e110>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a107046e750>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070470fd0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070432250>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070482150>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070481690>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a107046e950>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070ab5850>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10602f6710>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a107032e010>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10703bf2d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a107041ce10>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070472550>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a106035ac90>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a106036d690>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1070ab4a50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1060384b50>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a1060385610>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10703bfcd0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10603a5490>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10603a7f10>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10603c49d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10603c73d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10603c7e90>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10601e7290>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10601e7d10>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10601fe710>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10601ff1d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10704a9dd0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a10602126d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a106032ad10>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a106032b7d0>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/coccidioidomycosis', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n",
            "<condyloma_acuminatum-class> condyloma acuminatum\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 02:14:51.547174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740276891.568205   80450 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740276891.574524   80450 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 02:14:51.595594: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 02:14:54 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'thresholding', 'dynamic_thresholding_ratio', 'timestep_spacing', 'sample_max_value', 'variance_type', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'num_attention_heads', 'class_embeddings_concat', 'transformer_layers_per_block', 'conv_in_kernel', 'resnet_out_scale_factor', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'encoder_hid_dim', 'resnet_skip_time_act', 'conv_out_kernel', 'addition_embed_type_num_heads', 'upcast_attention', 'mid_block_type', 'time_embedding_type', 'encoder_hid_dim_type', 'dropout', 'reverse_transformer_layers_per_block', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'attention_type', 'cross_attention_norm', 'time_embedding_dim', 'class_embed_type', 'addition_time_embed_dim', 'addition_embed_type', 'time_embedding_act_fn', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e74384450>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68cb2a10>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68c95ed0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68c97190>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68caf550>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68cad410>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68b172d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68c5f250>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c322050>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c322b10>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c33d290>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c33dd50>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c389b90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68c8a810>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3a1050>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3a1b10>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3b8590>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3b9050>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3d04d0>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3d0f90>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3d39d0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3f44d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c3f6f10>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68c5fd50>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c212ed0>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c213990>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c22a3d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68c8b0d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c241850>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c242310>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e68cae750>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7f4e4c357090>\n",
            "750\n",
            "02/23/2025 02:17:14 - INFO - __main__ - ***** Running training *****\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Num examples = 96\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Num instance images = 1\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Num Epochs = 125\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/23/2025 02:17:14 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [10:22<21:11,  2.54s/it, loss=0.589, lr=5e-6]02/23/2025 02:27:37 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/23/2025 02:27:37 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250/optimizer.bin\n",
            "02/23/2025 02:27:37 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250/scheduler.bin\n",
            "02/23/2025 02:27:37 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250/sampler.bin\n",
            "02/23/2025 02:27:37 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250/scaler.pt\n",
            "02/23/2025 02:27:37 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250/random_states_0.pkl\n",
            "02/23/2025 02:27:37 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-250\n",
            "Steps:  67% 500/750 [20:53<10:36,  2.54s/it, loss=0.319, lr=5e-6]02/23/2025 02:38:08 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 02:38:08 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500/optimizer.bin\n",
            "02/23/2025 02:38:08 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500/scheduler.bin\n",
            "02/23/2025 02:38:08 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500/sampler.bin\n",
            "02/23/2025 02:38:08 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500/scaler.pt\n",
            "02/23/2025 02:38:08 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 02:38:08 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-500\n",
            "Steps: 100% 750/750 [31:22<00:00,  2.43s/it, loss=0.304, lr=5e-6]02/23/2025 02:48:37 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 02:48:37 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750/optimizer.bin\n",
            "02/23/2025 02:48:37 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750/scheduler.bin\n",
            "02/23/2025 02:48:37 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750/sampler.bin\n",
            "02/23/2025 02:48:37 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750/scaler.pt\n",
            "02/23/2025 02:48:37 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 02:48:37 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/checkpoint-750\n",
            "Steps: 100% 750/750 [31:22<00:00,  2.43s/it, loss=0.282, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/condyloma acuminatum/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [31:22<00:00,  2.51s/it, loss=0.282, lr=5e-6]\n",
            "<cutaneous_T-cell_lymphoma-class> cutaneous T-cell lymphoma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 02:48:49.971974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740278929.993369   88820 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740278929.999923   88820 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 02:48:50.021974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 02:48:52 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'dynamic_thresholding_ratio', 'timestep_spacing', 'clip_sample_range', 'variance_type', 'sample_max_value', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'mid_block_type', 'encoder_hid_dim_type', 'time_embedding_type', 'time_embedding_dim', 'time_embedding_act_fn', 'reverse_transformer_layers_per_block', 'dropout', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'timestep_post_act', 'resnet_skip_time_act', 'addition_embed_type', 'mid_block_only_cross_attention', 'time_cond_proj_dim', 'addition_time_embed_dim', 'upcast_attention', 'addition_embed_type_num_heads', 'class_embeddings_concat', 'resnet_time_scale_shift', 'attention_type', 'cross_attention_norm', 'conv_out_kernel', 'transformer_layers_per_block', 'num_attention_heads', 'encoder_hid_dim', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20bcd150>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20bcc450>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c212650>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20bab7d0>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d2ca84c90>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b97c90>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c2151d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20bb5ed0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b0fd50>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b0f3d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c210550>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c258c90>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c2a4b10>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b0fe90>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c2a7f10>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c2bc9d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b558d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d2ca85090>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20bb7510>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d2ca85310>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c2f6710>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c2f71d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c119bd0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c212790>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b0f350>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c12e4d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c144f10>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d20b0f2d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c1643d0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c164e90>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d0c275550>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7a0d2ca84d10>\n",
            "750\n",
            "02/23/2025 02:51:16 - INFO - __main__ - ***** Running training *****\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Num examples = 96\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Num instance images = 29\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Num Epochs = 125\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/23/2025 02:51:16 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [11:07<21:45,  2.61s/it, loss=0.57, lr=5e-6]02/23/2025 03:02:23 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/23/2025 03:02:23 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250/optimizer.bin\n",
            "02/23/2025 03:02:23 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250/scheduler.bin\n",
            "02/23/2025 03:02:23 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250/sampler.bin\n",
            "02/23/2025 03:02:23 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250/scaler.pt\n",
            "02/23/2025 03:02:23 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250/random_states_0.pkl\n",
            "02/23/2025 03:02:23 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-250\n",
            "Steps:  67% 500/750 [21:58<10:56,  2.63s/it, loss=0.32, lr=5e-6]02/23/2025 03:13:14 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 03:13:15 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500/optimizer.bin\n",
            "02/23/2025 03:13:15 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500/scheduler.bin\n",
            "02/23/2025 03:13:15 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500/sampler.bin\n",
            "02/23/2025 03:13:15 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500/scaler.pt\n",
            "02/23/2025 03:13:15 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 03:13:15 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-500\n",
            "Steps: 100% 750/750 [32:49<00:00,  2.49s/it, loss=0.299, lr=5e-6]02/23/2025 03:24:05 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 03:24:05 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750/optimizer.bin\n",
            "02/23/2025 03:24:05 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750/scheduler.bin\n",
            "02/23/2025 03:24:05 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750/sampler.bin\n",
            "02/23/2025 03:24:05 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750/scaler.pt\n",
            "02/23/2025 03:24:05 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 03:24:05 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/checkpoint-750\n",
            "Steps: 100% 750/750 [32:49<00:00,  2.49s/it, loss=0.296, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/cutaneous T-cell lymphoma/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [32:49<00:00,  2.63s/it, loss=0.296, lr=5e-6]\n",
            "<dermatofibroma-class> dermatofibroma\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 03:24:17.770994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740281057.791302   97562 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740281057.797384   97562 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 03:24:17.818061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 03:24:20 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'timestep_spacing', 'thresholding', 'dynamic_thresholding_ratio', 'clip_sample_range', 'variance_type', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'addition_embed_type', 'cross_attention_norm', 'conv_out_kernel', 'mid_block_type', 'dropout', 'projection_class_embeddings_input_dim', 'attention_type', 'encoder_hid_dim_type', 'transformer_layers_per_block', 'conv_in_kernel', 'reverse_transformer_layers_per_block', 'class_embed_type', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'resnet_time_scale_shift', 'time_embedding_type', 'time_cond_proj_dim', 'num_attention_heads', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'timestep_post_act', 'addition_time_embed_dim', 'resnet_out_scale_factor', 'class_embeddings_concat', 'time_embedding_dim', 'upcast_attention', 'time_embedding_act_fn'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776539d90>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7764ea2d0>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7763e5290>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776379350>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776557550>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776554ad0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f774076210>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f774076cd0>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f774096110>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776556f90>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7740b1310>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7740b1dd0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776545cd0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7740fe510>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7783de3d0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f776545d90>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f77412c3d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f77412ce90>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f774144350>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f774144e10>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f774147890>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7764e87d0>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f76830ad50>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7764f5510>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f768326c90>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f768327750>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f76833e1d0>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f76833ec90>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f768351710>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7683521d0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7740ce610>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x78f7740cf0d0>\n",
            "750\n",
            "02/23/2025 03:26:31 - INFO - __main__ - ***** Running training *****\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Num examples = 96\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Num instance images = 19\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Num batches each epoch = 6\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Num Epochs = 125\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/23/2025 03:26:31 - INFO - __main__ -   Total optimization steps = 750\n",
            "Steps:  33% 250/750 [11:35<23:03,  2.77s/it, loss=0.55, lr=5e-6]02/23/2025 03:38:06 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250/pytorch_lora_weights.safetensors\n",
            "02/23/2025 03:38:07 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250/optimizer.bin\n",
            "02/23/2025 03:38:07 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250/scheduler.bin\n",
            "02/23/2025 03:38:07 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250/sampler.bin\n",
            "02/23/2025 03:38:07 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250/scaler.pt\n",
            "02/23/2025 03:38:07 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250/random_states_0.pkl\n",
            "02/23/2025 03:38:07 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-250\n",
            "Steps:  67% 500/750 [23:04<11:36,  2.79s/it, loss=0.308, lr=5e-6]02/23/2025 03:49:35 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "02/23/2025 03:49:35 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500/optimizer.bin\n",
            "02/23/2025 03:49:35 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500/scheduler.bin\n",
            "02/23/2025 03:49:35 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500/sampler.bin\n",
            "02/23/2025 03:49:35 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500/scaler.pt\n",
            "02/23/2025 03:49:35 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500/random_states_0.pkl\n",
            "02/23/2025 03:49:35 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-500\n",
            "Steps: 100% 750/750 [34:30<00:00,  2.57s/it, loss=0.309, lr=5e-6]02/23/2025 04:01:02 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750\n",
            "Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750/pytorch_lora_weights.safetensors\n",
            "02/23/2025 04:01:02 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750/optimizer.bin\n",
            "02/23/2025 04:01:02 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750/scheduler.bin\n",
            "02/23/2025 04:01:02 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750/sampler.bin\n",
            "02/23/2025 04:01:02 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750/scaler.pt\n",
            "02/23/2025 04:01:02 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750/random_states_0.pkl\n",
            "02/23/2025 04:01:02 - INFO - __main__ - Saved state to /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/checkpoint-750\n",
            "Steps: 100% 750/750 [34:30<00:00,  2.57s/it, loss=0.266, lr=5e-6]Model weights saved in /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatofibroma/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 750/750 [34:30<00:00,  2.76s/it, loss=0.266, lr=5e-6]\n",
            "<dermatomyositis-class> dermatomyositis\n",
            "[*] Weights will be saved at /content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatomyositis\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-23 04:01:14.380733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740283274.401570  106667 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740283274.407808  106667 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-23 04:01:14.429070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "02/23/2025 04:01:17 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "{'timestep_spacing', 'variance_type', 'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "{'encoder_hid_dim_type', 'attention_type', 'num_attention_heads', 'timestep_post_act', 'class_embeddings_concat', 'reverse_transformer_layers_per_block', 'time_embedding_act_fn', 'time_cond_proj_dim', 'encoder_hid_dim', 'mid_block_type', 'resnet_out_scale_factor', 'time_embedding_dim', 'transformer_layers_per_block', 'addition_time_embed_dim', 'projection_class_embeddings_input_dim', 'dropout', 'class_embed_type', 'addition_embed_type_num_heads', 'addition_embed_type', 'conv_out_kernel', 'upcast_attention', 'time_embedding_type', 'resnet_time_scale_shift', 'resnet_skip_time_act', 'mid_block_only_cross_attention', 'cross_attention_norm', 'conv_in_kernel'} was not found in config. Values will be initialized to default values.\n",
            "/content/miccai-2025/train_lora.py:790: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  for token, token_embedding in torch.load(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407d0610>\n",
            "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407c7410>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407b3990>\n",
            "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407a3390>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793742662510>\n",
            "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407ba7d0>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937302fc350>\n",
            "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937302fce10>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730314290>\n",
            "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730314d50>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937303174d0>\n",
            "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730317fd0>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407bbd10>\n",
            "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937303784d0>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79373037af10>\n",
            "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79373037b9d0>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730392410>\n",
            "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407baf50>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407fa810>\n",
            "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937303aadd0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407f9ad0>\n",
            "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407fa450>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407c4d10>\n",
            "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937303ed790>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730200c90>\n",
            "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730201750>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x7937407f8590>\n",
            "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793740713cd0>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79373021b650>\n",
            "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x79373021bfd0>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730344850>\n",
            "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers.models.attention_processor.AttnProcessor2_0 object at 0x793730345310>\n",
            "No instance images found in the provided instance_data_dir.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1172, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 762, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--output_dir=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/lora/ddi_2/ti_lora_SEED=0/dermatomyositis', '--revision=fp16', '--seed=0', '--resolution=256', '--train_batch_size=16', '--with_prior_preservation', '--num_class_images=96', '--sample_batch_size=16', '--mixed_precision=fp16', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=750', '--checkpointing_steps=250', '--concepts_list=ti_lora_concepts_list_seed=ddi_1_0.json', '--rank=8', '--embed_path=/content/drive/MyDrive/ucsc_drive/UCSC/Winter 2025/ti/ddi_1/SEED=0/aggregated_embeds_SEED=0.pt']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4OplN-2GRj68"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}